### 期望与方差

#### 1. 核心概念

**期望（Expectation）**：期望是一个随机变量取值的加权平均数，它反映了随机变量的平均水平或中心趋势。在概率论中，设随机变量 $X$ 的概率密度函数为 $p(x)$，则其期望值定义为：

$$
\mathbb{E}[X] = \sum_{x} x \cdot p(x) \quad \text{(离散情况)}
$$
$$
\mathbb{E}[X] = \int_{-\infty}^{\infty} x \cdot p(x) \, dx \quad \text{(连续情况)}
$$


- 线性运算： $E(ax+by+c) = aE(x)+bE(y)+c$  
- 推广形式： $E(\sum_{k=1}^{n}{a_ix_i+c}) = \sum_{k=1}^{n}{a_iE(x_i)+c}$ 



**方差（Variance）**：方差描述了随机变量与其期望值之间的偏离程度。它衡量了数据的离散程度，即数值的波动情况。设$X$为服从分布$F$的随机变量，如果$E[X]$是随机变量X的期望（均值$μ=E[X]$），则随机变量X或者分布F的方差为X的离差平方的期望,随机变量 $X$ 的方差 $\text{Var}(X)$ 定义为：

$$
\text{Var}(X) = \mathbb{E}[(X - \mu)^2] =\mathbb{E}[(X - \mathbb{E}[X])^2]= \mathbb{E}[X^2] - (\mathbb{E}[X])^2 
$$


**协方差（Covariance）**：是用于衡量两个变量之间的线性关系的一种统计量。它描述了当一个变量变化时，另一个变量的变化方向和程度。如果协方差为正，说明两个变量呈正相关关系；如果协方差为负，说明两个变量呈负相关关系；如果协方差接近于零，说明两个变量之间没有明显的线性关系。 定义为：

$$ \text{Cov}(X, Y) = \mathbb{E}[(X - \mu_X)(Y - \mu_Y)] $$


如果协方差是基于样本数据计算的,它也可以通过以下公式计算：

$$ \text{Cov}(X, Y) = \frac{1}{n-1} \sum_{i=1}^{n} (x_i - \mu_X)(y_i - \mu_Y) $$

为什么需要减去 1?

- 样本均值的影响：当我们计算样本方差时，样本均值 μ 是基于样本本身计算的，而不是总体的真实均值。由于样本均值是根据样本数据得出的，它比真实均值更接近样本数据，导致每个数据点与样本均值的偏差（误差）变小，进而导致方差的低估。

- 自由度的概念：方差中的自由度可以理解为我们能够独立选择的样本数量。由于样本均值是从数据中计算出来的，这限制了数据点的独立性。样本中的 n 个数据点只有 n−1个可以独立变化，最后一个数据点必须与样本均值保持一致。因此，我们用 n−1 来补偿自由度的减少。

#### 2. 代码实现

在 Python 中可以通过 `numpy` 或 `pytorch` 等库来计算期望和方差。下面是使用 `numpy` 计算期望和方差的示例代码：

```python
import numpy as np

# 生成一组随机变量
data = np.array([1, 2, 3, 4, 5])

# 计算期望值
expectation = np.mean(data)

# 计算方差
variance = np.var(data)

print("期望值: ", expectation)
print("方差: ", variance)
```

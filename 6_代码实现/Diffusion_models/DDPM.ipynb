{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDPM\n",
    "## Denoising Diffusion Probabilistic Models\n",
    "简单来说，我们从数据中获得一张图像，并逐步添加噪声。然后训练一个模型在每个步骤中预测这些噪声，并利用该模型来生成图像。\n",
    "\n",
    "## 正向过程\n",
    "\n",
    "正向过程在 $T$ 个时间步中为数据 $x_0 \\sim q(x_0)$ 添加噪声。\n",
    "\n",
    "\\[\n",
    "q(x_t | x_{t-1}) = \\mathcal{N}\\big(x_t; \\sqrt{1-  \\beta_t} x_{t-1}, \\beta_t \\mathbf{I}\\big) \\\\\n",
    "\\]\n",
    "\\[\n",
    "q(x_{1:T} | x_0) = \\prod_{t = 1}^{T} q(x_t | x_{t-1})\n",
    "\\]\n",
    "\n",
    "其中 $\\beta_1, \\dots, \\beta_T$ 是方差调度。\n",
    "\n",
    "我们可以在任意时间步 $t$ 采样 $x_t$，公式如下：\n",
    "\n",
    "\\[\n",
    "q(x_t|x_0) = \\mathcal{N} \\Big(x_t; \\sqrt{\\bar\\alpha_t} x_0, (1-\\bar\\alpha_t) \\mathbf{I} \\Big)\n",
    "\\]\n",
    "\n",
    "其中 $\\alpha_t = 1 - \\beta_t$，$\\bar\\alpha_t = \\prod_{s=1}^t \\alpha_s$。\n",
    "\n",
    "\n",
    "## 逆过程\n",
    "\n",
    "逆过程从 $p(x_T) = \\mathcal{N}(x_T; \\mathbf{0}, \\mathbf{I})$ 开始，在 $T$ 个时间步中去除噪声。\n",
    "\n",
    "\\[\n",
    "\\textcolor{lightgreen}{p_\\theta}(x_{t-1} | x_t) = \\mathcal{N}\\big(x_{t-1}; \\textcolor{lightgreen}{\\mu_\\theta}(x_t, t), \\textcolor{lightgreen}{\\Sigma_\\theta}(x_t, t)\\big)\n",
    "\\]\n",
    "\\[\n",
    "\\textcolor{lightgreen}{p_\\theta}(x_{0:T}) = \\textcolor{lightgreen}{p_\\theta}(x_T) \\prod_{t = 1}^{T} \\textcolor{lightgreen}{p_\\theta}(x_{t-1} | x_t)\n",
    "\\]\n",
    "\\[\n",
    "\\textcolor{lightgreen}{p_\\theta}(x_0) = \\int \\textcolor{lightgreen}{p_\\theta}(x_{0:T}) \\, dx_{1:T}\n",
    "\\]\n",
    "\n",
    "$\\textcolor{lightgreen}{\\theta}$ 是我们训练的参数。\n",
    "\n",
    "## 损失函数\n",
    "\n",
    "我们通过优化负对数似然上的ELBO（源自詹森不等式）。\n",
    "\n",
    "\\[\n",
    "\\mathbb{E}[-\\log \\textcolor{lightgreen}{p_\\theta}(x_0)]\n",
    " \\le \\mathbb{E}_q \\left[ -\\log \\frac{\\textcolor{lightgreen}{p_\\theta}(x_{0:T})}{q(x_{1:T}|x_0)} \\right] = L\n",
    "\\]\n",
    "\n",
    "损失可以重写如下：\n",
    "\n",
    "\\[\n",
    "L = \\mathbb{E}_q \\left[ -\\log \\frac{\\textcolor{lightgreen}{p_\\theta}(x_{0:T})}{q(x_{1:T}|x_0)} \\right] \n",
    "= \\mathbb{E}_q \\left[ -\\log p(x_T) - \\sum_{t=1}^T \\log \\frac{\\textcolor{lightgreen}{p_\\theta}(x_{t-1}|x_t)}{q(x_t|x_{t-1})} \\right] \n",
    "\\]\n",
    "\n",
    "\\[\n",
    "= \\mathbb{E}_q \\left[ -\\log \\frac{p(x_T)}{q(x_T|x_0)} - \\sum_{t=2}^T \\log \\frac{\\textcolor{lightgreen}{p_\\theta}(x_{t-1}|x_t)}{q(x_{t-1}|x_t,x_0)} -\\log \\textcolor{lightgreen}{p_\\theta}(x_0|x_1) \\right] \n",
    "\\]\n",
    "\n",
    "\\[\n",
    "= \\mathbb{E}_q \\left[ D_{KL}(q(x_T|x_0) \\Vert p(x_T)) + \\sum_{t=2}^T D_{KL}(q(x_{t-1}|x_t,x_0) \\Vert \\textcolor{lightgreen}{p_\\theta}(x_{t-1}|x_t)) -\\log \\textcolor{lightgreen}{p_\\theta}(x_0|x_1) \\right]\n",
    "\\]\n",
    "\n",
    "由于我们保持 $\\beta_1, \\dots, \\beta_T$ 为常数，因此 $D_{KL}(q(x_T|x_0) \\Vert p(x_T))$ 是一个常数。\n",
    "\n",
    "### Computing $L_{t-1} = D_{KL}(q(x_{t-1}|x_t,x_0) \\Vert \\textcolor{lightgreen}{p_\\theta}(x_{t-1}|x_t))$\n",
    "\n",
    "The forward process posterior conditioned by $x_0$ is,\n",
    "\n",
    "\\begin{align}\n",
    "q(x_{t-1}|x_t, x_0) &= \\mathcal{N} \\Big(x_{t-1}; \\tilde\\mu_t(x_t, x_0), \\tilde\\beta_t \\mathbf{I} \\Big) \\\\\n",
    "\\tilde\\mu_t(x_t, x_0) &= \\frac{\\sqrt{\\bar\\alpha_{t-1}}\\beta_t}{1 - \\bar\\alpha_t}x_0\n",
    "                         + \\frac{\\sqrt{\\alpha_t}(1 - \\bar\\alpha_{t-1})}{1-\\bar\\alpha_t}x_t \\\\\n",
    "\\tilde\\beta_t &= \\frac{1 - \\bar\\alpha_{t-1}}{1 - \\bar\\alpha_t} \\beta_t\n",
    "\\end{align}\n",
    "\n",
    "The paper sets $\\textcolor{lightgreen}{\\Sigma_\\theta}(x_t, t) = \\sigma_t^2 \\mathbf{I}$ where $\\sigma_t^2$ is set to constants\n",
    "$\\beta_t$ or $\\tilde\\beta_t$.\n",
    "\n",
    "Then,\n",
    "$$\\textcolor{lightgreen}{p_\\theta}(x_{t-1} | x_t) = \\mathcal{N}\\big(x_{t-1}; \\textcolor{lightgreen}{\\mu_\\theta}(x_t, t), \\sigma_t^2 \\mathbf{I} \\big)$$\n",
    "\n",
    "For given noise $\\epsilon \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})$ using $q(x_t|x_0)$\n",
    "\n",
    "\\begin{align}\n",
    "x_t(x_0, \\epsilon) &= \\sqrt{\\bar\\alpha_t} x_0 + \\sqrt{1-\\bar\\alpha_t}\\epsilon \\\\\n",
    "x_0 &= \\frac{1}{\\sqrt{\\bar\\alpha_t}} \\Big(x_t(x_0, \\epsilon) -  \\sqrt{1-\\bar\\alpha_t}\\epsilon\\Big)\n",
    "\\end{align}\n",
    "\n",
    "This gives,\n",
    "\n",
    "\\begin{align}\n",
    "L_{t-1}\n",
    " &= D_{KL}(q(x_{t-1}|x_t,x_0) \\Vert \\textcolor{lightgreen}{p_\\theta}(x_{t-1}|x_t)) \\\\\n",
    " &= \\mathbb{E}_q \\Bigg[ \\frac{1}{2\\sigma_t^2}\n",
    " \\Big \\Vert \\tilde\\mu(x_t, x_0) - \\textcolor{lightgreen}{\\mu_\\theta}(x_t, t) \\Big \\Vert^2 \\Bigg] \\\\\n",
    " &= \\mathbb{E}_{x_0, \\epsilon} \\Bigg[ \\frac{1}{2\\sigma_t^2}\n",
    "  \\bigg\\Vert \\frac{1}{\\sqrt{\\alpha_t}} \\Big(\n",
    "  x_t(x_0, \\epsilon) - \\frac{\\beta_t}{\\sqrt{1 - \\bar\\alpha_t}} \\epsilon\n",
    "  \\Big) - \\textcolor{lightgreen}{\\mu_\\theta}(x_t(x_0, \\epsilon), t) \\bigg\\Vert^2 \\Bigg] \\\\\n",
    "\\end{align}\n",
    "\n",
    "Re-parameterizing with a model to predict noise\n",
    "\n",
    "\\begin{align}\n",
    "\\textcolor{lightgreen}{\\mu_\\theta}(x_t, t) &= \\tilde\\mu \\bigg(x_t,\n",
    "  \\frac{1}{\\sqrt{\\bar\\alpha_t}} \\Big(x_t -\n",
    "   \\sqrt{1-\\bar\\alpha_t}\\textcolor{lightgreen}{\\epsilon_\\theta}(x_t, t) \\Big) \\bigg) \\\\\n",
    "  &= \\frac{1}{\\sqrt{\\alpha_t}} \\Big(x_t -\n",
    "  \\frac{\\beta_t}{\\sqrt{1-\\bar\\alpha_t}}\\textcolor{lightgreen}{\\epsilon_\\theta}(x_t, t) \\Big)\n",
    "\\end{align}\n",
    "\n",
    "where $\\epsilon_\\theta$ is a learned function that predicts $\\epsilon$ given $(x_t, t)$.\n",
    "\n",
    "This gives,\n",
    "\n",
    "\\begin{align}\n",
    "L_{t-1}\n",
    "&= \\mathbb{E}_{x_0, \\epsilon} \\Bigg[ \\frac{\\beta_t^2}{2\\sigma_t^2 \\alpha_t (1 - \\bar\\alpha_t)}\n",
    "  \\Big\\Vert\n",
    "  \\epsilon - \\textcolor{lightgreen}{\\epsilon_\\theta}(\\sqrt{\\bar\\alpha_t} x_0 + \\sqrt{1-\\bar\\alpha_t}\\epsilon, t)\n",
    "  \\Big\\Vert^2 \\Bigg]\n",
    "\\end{align}\n",
    "\n",
    "That is, we are training to predict the noise.\n",
    "\n",
    "### Simplified loss\n",
    "\n",
    "$$L_{\\text{simple}}(\\theta) = \\mathbb{E}_{t,x_0, \\epsilon} \\Bigg[ \\bigg\\Vert\n",
    "\\epsilon - \\textcolor{lightgreen}{\\epsilon_\\theta}(\\sqrt{\\bar\\alpha_t} x_0 + \\sqrt{1-\\bar\\alpha_t}\\epsilon, t)\n",
    "\\bigg\\Vert^2 \\Bigg]$$\n",
    "\n",
    "This minimizes $-\\log \\textcolor{lightgreen}{p_\\theta}(x_0|x_1)$ when $t=1$ and $L_{t-1}$ for $t\\gt1$ discarding the\n",
    "weighting in $L_{t-1}$. Discarding the weights $\\frac{\\beta_t^2}{2\\sigma_t^2 \\alpha_t (1 - \\bar\\alpha_t)}$\n",
    "increase the weight given to higher $t$ (which have higher noise levels), therefore increasing the sample quality.\n",
    "\n",
    "This file implements the loss calculation and a basic sampling method that we use to generate images during\n",
    "training.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

## 重要性采样（Importance Sampling）
是一种用于改进蒙特卡罗积分（Monte Carlo Integration）估计精度的技术，尤其是在一些概率密度函数的尾部表现不足时，可以大幅减少方差。

### 1. 核心概念
在蒙特卡罗估计中，我们通常是根据某个分布 $p(x)$ 来采样，然后对目标函数进行估计。然而，当目标函数的某些区域比其他区域更重要时，直接从 $p(x)$ 采样可能效率不高。**重要性采样**则通过从一个不同的分布 $q(x)$（通常称为**提议分布**）采样，并对采样结果加权，从而提高采样效率。

给定一个期望值的计算问题，目标是估计：
$$
I = \mathbb{E}_p[f(x)] = \int f(x)p(x) dx
$$
如果我们从 $p(x)$ 分布中采样，这个期望可以用蒙特卡罗估计：
$$
\hat{I} = \frac{1}{N} \sum_{i=1}^{N} f(x_i), \quad x_i \sim p(x)
$$

在重要性采样中，我们选择从一个更易于采样的分布 $q(x)$ 中采样，但要校正权重：
$$
\hat{I}_{IS} = \frac{1}{N} \sum_{i=1}^{N} \frac{f(x_i) p(x_i)}{q(x_i)}, \quad x_i \sim q(x)
$$
其中，权重 $w(x) = \frac{p(x)}{q(x)}$ 是用来校正从不同分布采样的偏差。

### 2. 常见问题与解答
- **如何选择提议分布 $q(x)$?**
  理想的提议分布应该与 $f(x)p(x)$ 的形状相近，尤其是在 $f(x)p(x)$ 最大的区域。选得不好会导致估计的方差增大。

- **为什么重要性采样能减少方差？**
  通过选择一个更加贴近目标分布的 $q(x)$，可以减少低概率区域的采样，从而减少方差。

- **当 $q(x)$ 与 $p(x)$ 的差异较大时会发生什么？**
  如果 $q(x)$ 与 $p(x)$ 差异较大，可能会导致权重 $ \frac{p(x)}{q(x)} $ 非常大，从而使估计器的方差急剧上升。

### 3. 代码实现

下面是一个简单的Python实现，使用重要性采样来估计一个目标分布的期望值。

```python
import numpy as np

# 目标函数 f(x)
def f(x):
    return np.exp(-x**2)

# 目标分布 p(x): 正态分布
def p(x):
    return (1/np.sqrt(2*np.pi)) * np.exp(-0.5 * x**2)

# 提议分布 q(x): 均匀分布
def q(x):
    return np.ones_like(x) / 10  # 区间 [-5, 5] 的均匀分布

# 重要性采样
def importance_sampling(num_samples):
    # 从提议分布 q(x) 中采样
    samples = np.random.uniform(-5, 5, num_samples)
    
    # 计算权重 w(x) = p(x) / q(x)
    weights = p(samples) / q(samples)
    
    # 重要性采样估计
    estimate = np.mean(f(samples) * weights)
    
    return estimate

# 执行重要性采样
num_samples = 10000
result = importance_sampling(num_samples)
print(f"重要性采样估计的期望值: {result}")
```

### 4. 数学公式推导

**蒙特卡罗估计的标准形式：**
$$
\hat{I} = \frac{1}{N} \sum_{i=1}^{N} f(x_i), \quad x_i \sim p(x)
$$

**重要性采样估计：**
$$
\hat{I}_{IS} = \frac{1}{N} \sum_{i=1}^{N} \frac{f(x_i) p(x_i)}{q(x_i)}, \quad x_i \sim q(x)
$$
这里的推导关键在于，期望值的定义：
$$
I = \int f(x) p(x) dx
$$
可以通过引入 $ q(x) $ 进行重写：
$$
I = \int f(x) \frac{p(x)}{q(x)} q(x) dx = \mathbb{E}_q \left[ f(x) \frac{p(x)}{q(x)} \right]
$$
因此我们可以从 $ q(x) $ 采样，并使用权重来校正结果。

---

